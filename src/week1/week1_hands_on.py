"""
1ì£¼ì°¨ ì‹¤ìŠµ: ì„ë² ë”©ê³¼ ë²¡í„° ê²€ìƒ‰ ê¸°ì´ˆ
RAGì˜ í•µì‹¬ ê°œë…ì„ ê°„ë‹¨í•œ ì˜ˆì œë¡œ ì´í•´í•˜ê¸°
"""

import sys
import io
import numpy as np
from typing import List, Tuple

# UTF-8 ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

print("=" * 80)
print("ğŸ¯ 1ì£¼ì°¨ ì‹¤ìŠµ: RAG í•µì‹¬ ê°œë… ì²´í—˜í•˜ê¸°")
print("=" * 80)

# ============================================================================
# Part 1: ì„ë² ë”©ì˜ ê¸°ë³¸ ê°œë…
# ============================================================================
print("\n\nğŸ“š Part 1: ì„ë² ë”©ì´ë€ ë¬´ì—‡ì¸ê°€?")
print("-" * 80)

# ê°„ë‹¨í•œ ì˜ˆì‹œ: ë‹¨ì–´ë¥¼ 2ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„
# ì‹¤ì œë¡œëŠ” ìˆ˜ë°±~ìˆ˜ì²œ ì°¨ì›ì´ì§€ë§Œ, ì´í•´ë¥¼ ìœ„í•´ 2ì°¨ì›ìœ¼ë¡œ ë‹¨ìˆœí™”

word_embeddings = {
    "ê°•ì•„ì§€": np.array([0.8, 0.9]),  # ë™ë¬¼, ê·€ì—¬ì›€
    "ê³ ì–‘ì´": np.array([0.9, 0.85]), # ë™ë¬¼, ê·€ì—¬ì›€
    "í«": np.array([0.85, 0.8]),     # ë™ë¬¼, ë°˜ë ¤ë™ë¬¼
    "ìë™ì°¨": np.array([0.1, 0.2]),  # íƒˆê²ƒ, ê¸°ê³„
    "ë¹„í–‰ê¸°": np.array([0.15, 0.1]), # íƒˆê²ƒ, ê¸°ê³„
}

print("\në‹¨ì–´ë“¤ì˜ ë²¡í„° í‘œí˜„:")
for word, vec in word_embeddings.items():
    print(f"  {word:6s} â†’ {vec}")

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°"""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)

print("\n\nì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°:")
print("  (1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬, 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‹¤ë¦„)")

# ê°•ì•„ì§€ì™€ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì˜ ìœ ì‚¬ë„
dog_vec = word_embeddings["ê°•ì•„ì§€"]
print(f"\n  'ê°•ì•„ì§€'ì™€ì˜ ìœ ì‚¬ë„:")
for word, vec in word_embeddings.items():
    if word != "ê°•ì•„ì§€":
        similarity = cosine_similarity(dog_vec, vec)
        print(f"    ê°•ì•„ì§€ â†” {word:6s}: {similarity:.4f}")

print("\n  ğŸ’¡ í•´ì„:")
print("     - 'ê³ ì–‘ì´', 'í«'ì€ 0.99ë¡œ ë§¤ìš° ìœ ì‚¬ (ê°™ì€ ì¹´í…Œê³ ë¦¬)")
print("     - 'ìë™ì°¨', 'ë¹„í–‰ê¸°'ëŠ” 0.3~0.4ë¡œ ë§¤ìš° ë‹¤ë¦„ (ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬)")


# ============================================================================
# Part 2: ë²¡í„° ê²€ìƒ‰ (Retrieval) ì‹œë®¬ë ˆì´ì…˜
# ============================================================================
print("\n\n" + "=" * 80)
print("ğŸ” Part 2: ë²¡í„° ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜")
print("-" * 80)

# ê°„ë‹¨í•œ ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ (ì‹¤ì œë¡œëŠ” ìˆ˜ì²œ~ìˆ˜ë§Œ ê°œ)
documents = {
    "doc1": "ê°•ì•„ì§€ëŠ” ì¶©ì„±ìŠ¤ëŸ¬ìš´ ë°˜ë ¤ë™ë¬¼ì…ë‹ˆë‹¤",
    "doc2": "ê³ ì–‘ì´ëŠ” ë…ë¦½ì ì¸ ì„±ê²©ì„ ê°€ì§„ ë™ë¬¼ì…ë‹ˆë‹¤",
    "doc3": "ìë™ì°¨ëŠ” í¸ë¦¬í•œ êµí†µìˆ˜ë‹¨ì…ë‹ˆë‹¤",
    "doc4": "ë¹„í–‰ê¸°ëŠ” ë¹ ë¥¸ ì¥ê±°ë¦¬ ì´ë™ì— ì í•©í•©ë‹ˆë‹¤",
    "doc5": "ë°˜ë ¤ë™ë¬¼ì„ í‚¤ìš°ë ¤ë©´ ì±…ì„ê°ì´ í•„ìš”í•©ë‹ˆë‹¤",
}

# ê°„ë‹¨í•œ ì„ë² ë”© ìƒì„± (ì‹¤ì œë¡œëŠ” ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©)
# ì—¬ê¸°ì„œëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ìˆœí™”
def simple_embed(text: str) -> np.ndarray:
    """ë‹¨ìˆœí™”ëœ ì„ë² ë”©: í‚¤ì›Œë“œ ê¸°ë°˜"""
    vec = np.array([0.0, 0.0])
    
    # ë™ë¬¼ ê´€ë ¨ í‚¤ì›Œë“œ
    animal_keywords = ["ê°•ì•„ì§€", "ê³ ì–‘ì´", "ë™ë¬¼", "ë°˜ë ¤", "í«"]
    for keyword in animal_keywords:
        if keyword in text:
            vec[0] += 0.3
    
    # íƒˆê²ƒ ê´€ë ¨ í‚¤ì›Œë“œ
    vehicle_keywords = ["ìë™ì°¨", "ë¹„í–‰ê¸°", "êµí†µ", "ì´ë™"]
    for keyword in vehicle_keywords:
        if keyword in text:
            vec[1] += 0.3
    
    # ì •ê·œí™”
    norm = np.linalg.norm(vec)
    if norm > 0:
        vec = vec / norm
    
    return vec

# ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜
doc_embeddings = {}
print("\në¬¸ì„œë“¤ì˜ ë²¡í„° í‘œí˜„:")
for doc_id, text in documents.items():
    vec = simple_embed(text)
    doc_embeddings[doc_id] = vec
    print(f"  {doc_id}: {text[:30]:30s} â†’ {vec}")

# ê²€ìƒ‰ í•¨ìˆ˜
def search(query: str, top_k: int = 3) -> List[Tuple[str, str, float]]:
    """ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
    query_vec = simple_embed(query)
    
    # ëª¨ë“  ë¬¸ì„œì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    for doc_id, doc_vec in doc_embeddings.items():
        sim = cosine_similarity(query_vec, doc_vec)
        similarities.append((doc_id, documents[doc_id], sim))
    
    # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    similarities.sort(key=lambda x: x[2], reverse=True)
    
    return similarities[:top_k]

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
print("\n\nğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
queries = [
    "ë°˜ë ¤ë™ë¬¼ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
    "êµí†µìˆ˜ë‹¨ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”?",
]

for query in queries:
    print(f"\nì§ˆë¬¸: '{query}'")
    print("-" * 60)
    results = search(query, top_k=3)
    
    for i, (doc_id, text, score) in enumerate(results, 1):
        print(f"  {i}ìœ„ [{doc_id}] (ìœ ì‚¬ë„: {score:.4f})")
        print(f"       â†’ {text}")


# ============================================================================
# Part 3: RAG ì „ì²´ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜
# ============================================================================
print("\n\n" + "=" * 80)
print("ğŸ¤– Part 3: ê°„ë‹¨í•œ RAG ì‹œë®¬ë ˆì´ì…˜")
print("-" * 80)

def simple_rag(query: str) -> str:
    """ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ ì‹œë®¬ë ˆì´ì…˜"""
    
    print(f"\n[ë‹¨ê³„ 1] ì§ˆë¬¸: {query}")
    
    # ê²€ìƒ‰ (Retrieval)
    print(f"[ë‹¨ê³„ 2] ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰...")
    results = search(query, top_k=2)
    
    print(f"[ë‹¨ê³„ 3] ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ:")
    retrieved_docs = []
    for doc_id, text, score in results:
        print(f"         - {text} (ìœ ì‚¬ë„: {score:.4f})")
        retrieved_docs.append(text)
    
    # ìƒì„± (Generation) - ì‹¤ì œë¡œëŠ” LLM ì‚¬ìš©
    print(f"[ë‹¨ê³„ 4] LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...")
    
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì¡°í•© (ì‹¤ì œë¡œëŠ” LLMì´ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±)
    context = " ".join(retrieved_docs)
    answer = f"ê²€ìƒ‰ëœ ë¬¸ì„œì— ë”°ë¥´ë©´: {context}"
    
    return answer

# RAG ì‹¤í–‰
print("\n" + "=" * 60)
test_query = "ë°˜ë ¤ë™ë¬¼ì€ ì–´ë–¤ íŠ¹ì§•ì´ ìˆë‚˜ìš”?"
answer = simple_rag(test_query)

print(f"\n[ìµœì¢… ë‹µë³€]")
print(f"  {answer}")

print("\n" + "=" * 60)
print("ğŸ’¡ ì‹¤ì œ RAG ì‹œìŠ¤í…œì—ì„œëŠ”:")
print("   1. ì„ë² ë”©: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš© (ì˜ˆ: BGE, OpenAI)")
print("   2. ë²¡í„° DB: FAISS, ChromaDB ë“± ì „ë¬¸ DB ì‚¬ìš©")
print("   3. LLM: GPT, Claude ë“±ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±")
print("   4. ìˆ˜ì²œ~ìˆ˜ë°±ë§Œ ê°œì˜ ë¬¸ì„œì—ì„œ ë¹ ë¥´ê²Œ ê²€ìƒ‰")


# ============================================================================
# Part 4: ì‹¤ì „ ì¤€ë¹„ - í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì•ˆë‚´
# ============================================================================
print("\n\n" + "=" * 80)
print("ğŸ› ï¸ Part 4: ì‹¤ì „ RAG êµ¬ì¶•ì„ ìœ„í•œ í™˜ê²½ ì„¤ì •")
print("-" * 80)

print("""
ë‹¤ìŒ ì£¼ë¶€í„°ëŠ” ì‹¤ì œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤!

í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv rag_env
source rag_env/bin/activate  # Windows: rag_env\\Scripts\\activate

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install langchain
pip install langchain-community
pip install sentence-transformers
pip install faiss-cpu
pip install pypdf2
pip install numpy pandas
```

ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—­í• :
  - langchain: RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• í”„ë ˆì„ì›Œí¬
  - sentence-transformers: ê³ í’ˆì§ˆ ì„ë² ë”© ëª¨ë¸
  - faiss-cpu: ë¹ ë¥¸ ë²¡í„° ê²€ìƒ‰
  - pypdf2: PDF ë¬¸ì„œ ì²˜ë¦¬
""")


# ============================================================================
# 1ì£¼ì°¨ ì •ë¦¬
# ============================================================================
print("\n" + "=" * 80)
print("âœ… 1ì£¼ì°¨ í•™ìŠµ ì™„ë£Œ!")
print("=" * 80)

print("""
ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©:
  1. RAGì˜ 3ë‹¨ê³„: Indexing â†’ Retrieval â†’ Generation
  2. ì„ë² ë”©: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ë¥¼ ìˆ«ìë¡œ í‘œí˜„
  3. ë²¡í„° ê²€ìƒ‰: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ ì°¾ê¸°
  4. RAG ì „ì²´ íë¦„: ì§ˆë¬¸ â†’ ê²€ìƒ‰ â†’ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€

ë‹¤ìŒ ì£¼ ì˜ˆê³ :
  ğŸ“„ 2ì£¼ì°¨: PDF ë¬¸ì„œ ì²˜ë¦¬ì™€ ì²­í‚¹(Chunking)
  - ì‹¤ì œ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  - ë¬¸ì„œë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í• 
  - ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ í˜¼í•© ì²˜ë¦¬
""")

print("\nğŸ’ª ê³„ì† í™”ì´íŒ…í•˜ì„¸ìš”!")

